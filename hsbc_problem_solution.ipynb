{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Needed for running spark on Local computer\n",
    "\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing pyspark and creating Sparkcontext and SparkSession\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from datetime import datetime\n",
    "\n",
    "spark = SparkSession.builder.appName('testing').getOrCreate()\n",
    "sc = spark.sparkContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using SparkContext to import data lake file\n",
    "\n",
    "trades = sc.textFile(\"datalake_file.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events = trades.map(lambda t: t.split(\"|\") )\n",
    "\n",
    "#### Question 1: \n",
    "\n",
    "flat_events = events.flatMap(lambda trade: [event for event in trade] )\n",
    "flat_events.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FWD', 'SPOT']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Question 2:\n",
    "\n",
    "mapTypes = lambda array: [ array[0], datetime.strptime(array[1], '%d%m%Y:%H:%M'), float(array[2]) ]\n",
    "\n",
    "typed_flat_events = flat_events.flatMap(lambda event: [*map(mapTypes, [event.strip().split(\",\")])] )\n",
    "\n",
    "typed_flat_events.map(lambda x: x[0]).distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('FWD', 179.74), ('SPOT', 57.22)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Question 3 (Total amount for each product):\n",
    "\n",
    "typed_flat_events.map(lambda lst: (lst[0], lst[-1])).reduceByKey(lambda price1, price2: price1 + price2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('FWD', datetime.datetime(2016, 5, 29, 8, 1), 10.56),\n",
       " ('FWD', datetime.datetime(2016, 5, 29, 8, 1), 10.56),\n",
       " ('FWD', datetime.datetime(2016, 5, 29, 9, 1), 10.56),\n",
       " ('SPOT', datetime.datetime(2016, 5, 29, 9, 4), 11.56),\n",
       " ('FWD', datetime.datetime(2016, 5, 29, 10, 53), 11.23),\n",
       " ('FWD', datetime.datetime(2016, 5, 29, 11, 45), 11.23),\n",
       " ('SPOT', datetime.datetime(2016, 5, 29, 12, 30), 23.2),\n",
       " ('SPOT', datetime.datetime(2016, 5, 29, 12, 30), 11.23),\n",
       " ('SPOT', datetime.datetime(2016, 5, 29, 12, 30), 11.23),\n",
       " ('FWD', datetime.datetime(2016, 5, 29, 13, 20), 23.2),\n",
       " ('FWD', datetime.datetime(2016, 5, 29, 13, 20), 23.2),\n",
       " ('FWD', datetime.datetime(2016, 5, 29, 14, 34), 56.0),\n",
       " ('FWD', datetime.datetime(2016, 5, 29, 15, 40), 23.2)]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Question 4 (Sort events by time they occured)\n",
    "\n",
    "typed_flat_events.map(lambda lst: (lst[0], lst[1], lst[2]) ).sortBy(lambda event: event[1]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('FWD', 56.0), ('SPOT', 23.2)]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Question 7 (Maximum price for each product):\n",
    "\n",
    "typed_flat_events.map(lambda lst: (lst[0], lst[-1])).reduceByKey(lambda a, b: a if a>b else b).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('FWD', 10.56), ('SPOT', 11.23)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Question 8 (Minimum price for each product):\n",
    "\n",
    "typed_flat_events.map(lambda lst: (lst[0], lst[-1])).reduceByKey(lambda a, b: a if a<b else b).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[117] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trade_events = trades.map(lambda t: t.split(\"|\") ).map(lambda lst: [[*map(mapTypes, [x.strip().split(\",\")])][0] for x in lst])\n",
    "trades.map(lambda t: t.split(\"|\") ).flatMap(lambda lst: [[*map(mapTypes, [x.strip().split(\",\")])] for x in lst])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[44.989999999999995, 45.989999999999995, 100.99, 44.989999999999995]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Question 9 (Total amount for each trade)\n",
    "\n",
    "#trade_events.map(lambda trade: [ x[2] for x in trade] ).collect()\n",
    "trade_events.map(lambda trade: sum([ x[2] for x in trade]) ).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10.56, 11.23, 10.56, 10.56]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Question 9 (Min price of for each trade)\n",
    "\n",
    "trade_events.map(lambda trade: min([ x[2] for x in trade]) ).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[23.2, 23.2, 56.0, 23.2]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Question 9 (Max price for each trade)\n",
    "trade_events.map(lambda trade: max([ x[2] for x in trade]) ).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['FWD,29052016:08:01,10.56',\n",
       "  ' FWD,29052016:13:20,23.20',\n",
       "  ' FWD,29052016:14:34,56.00'],\n",
       " ['FWD,29052016:08:01,10.56', ' FWD,29052016:13:20,23.20']]"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Question 5 (For a givent event get related events that make up the trade)\n",
    "\n",
    "event = 'SPOT,29052016:12:30,11.23'\n",
    "trades.filter(lambda lst: event in lst).map(lambda trade: trade.split(\"|\")).map(lambda trades: [*filter(lambda k: event not in k, trades)] ).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Question #6 (Data needs to be save on hive) \n",
    "\n",
    "### Google DataProc Hadoop Cluster ###\n",
    "\n",
    "# File System\n",
    "\n",
    "# wget https://raw.githubusercontent.com/sakksoftware/hsbc/master/trades.csv\n",
    "# wget https://raw.githubusercontent.com/sakksoftware/hsbc/master/events.csv \n",
    "\n",
    "### Hadoop\n",
    "\n",
    "# hadoop fs -mkdir /user/kwadwosakyi/trades\n",
    "# hadoop fs -mkdir /user/kwadwosakyi/events\n",
    "# hadoop fs -put trades.csv /user/kwadwosakyi/trades\n",
    "# hadoop fs -put events.csv /user/kwadwosakyi/events\n",
    "\n",
    "### Hive \n",
    "# hive\n",
    "# create database if not exists hsbc_interview;\n",
    "# show databases;\n",
    "# use hsbc_interview;\n",
    "# create external table events(product String, time_stamp timestamp, price float) ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' location '/user/kwadwosakyi/events' ;\n",
    "# create external table trades(trades String) ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\n' location '/user/kwadwosakyi/trades' ;\n",
    "# show tables;\n",
    "# select * from events;\n",
    "# select * from trades\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df = typed_flat_events.toDF(['product', 'timestamp', 'price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-----+\n",
      "|product|          timestamp|price|\n",
      "+-------+-------------------+-----+\n",
      "|    FWD|2016-05-29 09:01:00|10.56|\n",
      "|    FWD|2016-05-29 10:53:00|11.23|\n",
      "|    FWD|2016-05-29 15:40:00| 23.2|\n",
      "|   SPOT|2016-05-29 09:04:00|11.56|\n",
      "|    FWD|2016-05-29 11:45:00|11.23|\n",
      "|   SPOT|2016-05-29 12:30:00| 23.2|\n",
      "|    FWD|2016-05-29 08:01:00|10.56|\n",
      "|   SPOT|2016-05-29 12:30:00|11.23|\n",
      "|    FWD|2016-05-29 13:20:00| 23.2|\n",
      "|    FWD|2016-05-29 14:34:00| 56.0|\n",
      "|    FWD|2016-05-29 08:01:00|10.56|\n",
      "|   SPOT|2016-05-29 12:30:00|11.23|\n",
      "|    FWD|2016-05-29 13:20:00| 23.2|\n",
      "+-------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "event_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Writing event dataframe to csv file\n",
    "\n",
    "event_df.coalesce(1).write.option(\"timestampFormat\", \"yyyy-MM-dd HH:mm:ss\").format(\"csv\").save(\"events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating schema for trades which maintains structure of events in trade\n",
    "\n",
    "### Importing types to be used to create schema and creating schema\n",
    "from pyspark.sql.types import *\n",
    "event_schema = StructType([\n",
    "    StructField(\"product\", StringType(), True),\n",
    "    StructField(\"timestamp\", TimestampType(), True),\n",
    "    StructField(\"price\", FloatType())\n",
    "])\n",
    "trade_schema = ArrayType(event_schema)\n",
    "\n",
    "### Creating dataframe from Schema\n",
    "df_full = spark.createDataFrame(trade_events, trade_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- product: string (nullable = true)\n",
      " |    |    |-- timestamp: timestamp (nullable = true)\n",
      " |    |    |-- price: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Displaying schema of trades with event structure\n",
    "df_full.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(value=[Row(product='FWD', timestamp=datetime.datetime(2016, 5, 29, 9, 1), price=10.5600004196167), Row(product='FWD', timestamp=datetime.datetime(2016, 5, 29, 10, 53), price=11.229999542236328), Row(product='FWD', timestamp=datetime.datetime(2016, 5, 29, 15, 40), price=23.200000762939453)])"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of selecting first trade\n",
    "df_full.select('value').collect()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting string of trades into list of trades for convenience\n",
    "trades_list = trades.map(lambda trade: [trade])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframe from list of trades\n",
    "trades_df = trades_list.toDF(['trades'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing list of trades to csv file\n",
    "trades_df.coalesce(1).write.format(\"csv\").save(\"trades\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
